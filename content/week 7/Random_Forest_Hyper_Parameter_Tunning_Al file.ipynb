{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "## multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "\n",
    "# read the data\n",
    "path=\"../../Data Processing/Data/\" # path to file relative to working directory\n",
    "numerical = pd.read_csv(path+'numerical.csv')\n",
    "categorical = pd.read_csv(path+'categorical.csv')\n",
    "targets = pd.read_csv(path+'target.csv')\n",
    "data = pd.concat([numerical, categorical, targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 42 # for reproducible shuffling\n",
    "TT_RATIO = 0.25 # test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TARGET_B'].value_counts() # distribution of target \"B\" (binary label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y\n",
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis=1)\n",
    "# split the data by type\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding (needed for SMOTE and sci-kit learn's random forest)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='if_binary').fit(categoricalX) #  drop the first category in each feature to reduce frame size\n",
    "encoded_categorical = pd.DataFrame(encoder.transform(categoricalX).toarray()) # encode\n",
    "X = pd.concat([numericalX, encoded_categorical], axis = 1) # rejoin\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TT_RATIO, random_state=RAND_STATE)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "# Now we can remove the column target d from the set of features\n",
    "X_train = X_train.drop(['TARGET_D'], axis=1)\n",
    "X_test = X_test.drop(['TARGET_D'],   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again we need to drop the null (we use the same shuffling)\n",
    "na_idx = X_train[X_train.isna().any(axis=1)].index\n",
    "X_train = pd.DataFrame(X_train).drop(na_idx)\n",
    "y_train = pd.DataFrame(y_train).drop(na_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.astype(str)\n",
    "y_train.columns = y_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "y_test.columns = y_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'min_samples_split': [80],\n",
    "    'min_samples_leaf' : [50],\n",
    "    'max_features': ['sqrt'],\n",
    "    ##'max_samples' : ['None', 0.5],\n",
    "   'max_depth':[3,5]\n",
    "    ## 'bootstrap':[True,False]\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=RAND_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_ #To check the best set of parameters returned\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Please check RandomSearch as another algorithm comparable to GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(random_state=RAND_STATE, **best_params)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Higher the score, the more important the feature is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "feature_names = list(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(feature_names, clf.feature_importances_)))\n",
    "df.columns = ['columns_name', 'score_feature_importance']\n",
    "df.sort_values(by=['score_feature_importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
